@misc{wei2023jailbroken,
    title={Jailbroken: How Does LLM Safety Training Fail?}, 
    author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
    year={2023},
    eprint={2307.02483},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2307.02483}, 
}

@misc{zou2023universal,
    title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
    author = {Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
    year = {2023},
    url = {https://llm-attacks.org},
}

@misc{yaser2023potential,
    title = {Potential Risks of ChatGPT: Implications for Counterterrorism and International Security},
    author = {Yaser Esmailzadeh},
    year = {2023},
    url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4461195},
}

@misc{openai2023redteaming,
    title = {Red Teaming Network},
    author = {OpenAI},
    year = {2023},
    url = {https://openai.com/blog/red-teaming-network},
}

@misc{eu2024aiact,
    title = {Regulation (EU) 2024/1689 laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)},
    author = {European Parliament and Council},
    year = {2024},
    url = {https://eur-lex.europa.eu/eli/reg/2024/1689/oj},
}

@misc{purpura2025building,
    title={Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models}, 
    author={Alberto Purpura and Sahil Wadhwa and Jesse Zymet and Akshay Gupta and Andy Luo and Melissa Kazemi Rad and Swapnil Shinde and Mohammad Shahed Sorower},
    year={2025},
    eprint={2503.01742},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2503.01742}, 
}

@misc{schoepf2025madmax,
    title={MAD-MAX: Modular And Diverse Malicious Attack MiXtures for Automated LLM Red Teaming}, 
    author={Stefan Schoepf and Muhammad Zaid Hameed and Ambrish Rawat and Kieran Fraser and Giulio Zizzo and Giandomenico Cornacchia and Mark Purcell},
    year={2025},
    eprint={2503.06253},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2503.06253}, 
}

@misc{belaire2025automatic,
    title={Automatic LLM Red Teaming}, 
    author={Roman Belaire and Arunesh Sinha and Pradeep Varakantham},
    year={2025},
    eprint={2508.04451},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2508.04451}, 
}

@misc{shaw2025agonistic,
    title={Agonistic Image Generation: Unsettling the Hegemony of Intention}, 
    author={Andrew Shaw and Andre Ye and Ranjay Krishna and Amy X. Zhang},
    year={2025},
    eprint={2502.15242},
    archivePrefix={arXiv},
    primaryClass={cs.HC},
    url={https://arxiv.org/abs/2502.15242}, 
}

@misc{munoz2024pyrit,
    title={PyRIT: A Framework for Security Risk Identification and Red Teaming in Generative AI System}, 
    author={Gary D. Lopez Munoz and Amanda J. Minnich and Roman Lutz and Richard Lundeen and Raja Sekhar Rao Dheekonda and Nina Chikanov and Bolor-Erdene Jagdagdorj and Martin Pouliot and Shiven Chawla and Whitney Maxwell and Blake Bullwinkel and Katherine Pratt and Joris de Gruyter and Charlotte Siska and Pete Bryan and Tori Westerhoff and Chang Kawaguchi and Christian Seifert and Ram Shankar Siva Kumar and Yonatan Zunger},
    year={2024},
    eprint={2410.02828},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2410.02828}, 
}

@misc{mazeika2024harmbench,
    title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
    author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
    year={2024},
    eprint={2402.04249},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2402.04249}, 
}

@misc{mehrotra2024tap,
    title={Tree of Attacks: Jailbreaking Black-Box LLMs Automatically}, 
    author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi},
    year={2024},
    eprint={2312.02119},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2312.02119}, 
}

@misc{liu2024promptinjection,
    title={Prompt Injection attack against LLM-integrated Applications}, 
    author={Yi Liu and Gelei Deng and Yuekang Li and Kailong Wang and Zihao Wang and Xiaofeng Wang and Tianwei Zhang and Yepang Liu and Haoyu Wang and Yan Zheng and Yang Liu},
    year={2024},
    eprint={2306.05499},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2306.05499}, 
}

@misc{liu2024automaticpi,
    title={Automatic and Universal Prompt Injection Attacks against Large Language Models}, 
    author={Xiaogeng Liu and Zhiyuan Yu and Yizhe Zhang and Ning Zhang and Chaowei Xiao},
    year={2024},
    eprint={2403.04957},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2403.04957}, 
}

@misc{kumar2025certifying,
    title={Certifying LLM Safety against Adversarial Prompting}, 
    author={Aounon Kumar and Chirag Agarwal and Suraj Srinivas and Aaron Jiaxun Li and Soheil Feizi and Himabindu Lakkaraju},
    year={2025},
    eprint={2309.02705},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2309.02705}, 
}

@misc{xue2023trojllm,
    title={TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models}, 
    author={Jiaqi Xue and Mengxin Zheng and Ting Hua and Yilin Shen and Yepeng Liu and Ladislau Boloni and Qian Lou},
    year={2023},
    eprint={2306.06815},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2306.06815}, 
}

@article{vaswani2017attention,
    author       = {Ashish Vaswani and
                    Noam Shazeer and
                    Niki Parmar and
                    Jakob Uszkoreit and
                    Llion Jones and
                    Aidan N. Gomez and
                    Lukasz Kaiser and
                    Illia Polosukhin},
    title        = {Attention Is All You Need},
    journal      = {CoRR},
    volume       = {abs/1706.03762},
    year         = {2017},
    url          = {http://arxiv.org/abs/1706.03762},
    eprinttype    = {arXiv},
    eprint       = {1706.03762},
    timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
    biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{perez2022ignore,
    title={Ignore Previous Prompt: Attack Techniques For Language Models}, 
    author={FÃ¡bio Perez and Ian Ribeiro},
    year={2022},
    eprint={2211.09527},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2211.09527}, 
}

@misc{owasp2025llm,
    title={LLM Prompt Injection Prevention Cheat Sheet},
    author={{OWASP Cheat Sheet Series}},
    year={2025},
    url={https://cheatsheetseries.owasp.org/cheatsheets/LLM_Prompt_Injection_Prevention_Cheat_Sheet.html},
}

@misc{owasp2025top,
    title={Top 10 Risk \& Mitigations for LLMs and Gen AI Apps},
    author={{OWASP Top 10 for LLMs}},
    year={2025},
    url={https://genai.owasp.org/llm-top-10},
}

@misc{derczynski2024garak,
    title={garak: A Framework for Security Probing Large Language Models}, 
    author={Leon Derczynski and Erick Galinkin and Jeffrey Martin and Subho Majumdar and Nanna Inie},
    year={2024},
    eprint={2406.11036},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2406.11036}, 
}

@misc{lu2024blending,
    title={Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM}, 
    author={Xiaoding Lu and Zongyi Liu and Adian Liusie and Vyas Raina and Vineet Mudupalli and Yuwen Zhang and William Beauchamp},
    year={2024},
    eprint={2401.02994},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2401.02994}, 
}

@misc{fedus2022switch,
    title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity}, 
    author={William Fedus and Barret Zoph and Noam Shazeer},
    year={2022},
    eprint={2101.03961},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2101.03961}, 
}

@misc{zhang2024scaling,
    title={When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method}, 
    author={Biao Zhang and Zhongtao Liu and Colin Cherry and Orhan Firat},
    year={2024},
    eprint={2402.17193},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2402.17193}, 
}

@misc{borgeaud2022improving,
    title={Improving language models by retrieving from trillions of tokens}, 
    author={Sebastian Borgeaud and Arthur Mensch and Jordan Hoffmann and Trevor Cai and Eliza Rutherford and Katie Millican and George van den Driessche and Jean-Baptiste Lespiau and Bogdan Damoc and Aidan Clark and Diego de Las Casas and Aurelia Guy and Jacob Menick and Roman Ring and Tom Hennigan and Saffron Huang and Loren Maggiore and Chris Jones and Albin Cassirer and Andy Brock and Michela Paganini and Geoffrey Irving and Oriol Vinyals and Simon Osindero and Karen Simonyan and Jack W. Rae and Erich Elsen and Laurent Sifre},
    year={2022},
    eprint={2112.04426},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2112.04426}, 
}

@misc{dettmers2023qlora,
    title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
    author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
    year={2023},
    eprint={2305.14314},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2305.14314}, 
}

@misc{stiennon2022learning,
    title={Learning to summarize from human feedback}, 
    author={Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
    year={2022},
    eprint={2009.01325},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2009.01325}, 
}

@misc{ouyang2022training,
    title={Training language models to follow instructions with human feedback}, 
    author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    year={2022},
    eprint={2203.02155},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2203.02155}, 
}

@misc{schulman2017proximal,
    title={Proximal Policy Optimization Algorithms}, 
    author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
    year={2017},
    eprint={1707.06347},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1707.06347}, 
}

@misc{rafailov2024direct,
    title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
    author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
    year={2024},
    eprint={2305.18290},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2305.18290}, 
}

@misc{lee2024rlaif,
    title={RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback}, 
    author={Harrison Lee and Samrat Phatale and Hassan Mansoor and Thomas Mesnard and Johan Ferret and Kellie Lu and Colton Bishop and Ethan Hall and Victor Carbune and Abhinav Rastogi and Sushant Prakash},
    year={2024},
    eprint={2309.00267},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2309.00267}, 
}

@misc{zhao2025siren,
    title={Siren: A Learning-Based Multi-Turn Attack Framework for Simulating Real-World Human Jailbreak Behaviors}, 
    author={Yi Zhao and Youzhi Zhang},
    year={2025},
    eprint={2501.14250},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2501.14250}, 
}

@misc{greshake2023not,
    title={Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection}, 
    author={Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and Christoph Endres and Thorsten Holz and Mario Fritz},
    year={2023},
    eprint={2302.12173},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2302.12173}, 
}

@misc{gerganovNDggml,
    title={GGML: A low-level tensor library for machine learning}, 
    author={Georgi Gerganov},
    year={n.d.},
    url={https://github.com/ggml-org/ggml},
}

@misc{gerganov2023gguf,
    title={GGUF: An Efficient File Format for Large Language Models}, 
    author={Georgi Gerganov},
    year={2023},
    url={https://github.com/ggml-org/ggml/blob/master/docs/gguf.md},
}