@misc{wei2023jailbroken,
    author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
    title = {Jailbroken: How Does LLM Safety Training Fail?},
    year = {2023},
    url = {https://arxiv.org/abs/2307.02483},
    urldate = {2025-11-10}
}

@misc{zou2023universal,
    author = {Zou, Andy and Wang, Zifan and Kolter, Zico and Fredrikson, Matt},
    title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
    year = {2023},
    url = {https://llm-attacks.org},
    urldate = {2025-10-15}
}

@misc{chen2023chatgpt,
    author = {Chen, Jiazuo and Jordan, Michael},
    title = {How Jailbreaks Work on ChatGPT},
    year = {2023},
    url = {https://www.lesswrong.com/posts/...},
    urldate = {2025-11-01}
}

@misc{openai2024redteaming,
    author = {{OpenAI}},
    title = {Red Teaming Network},
    year = {2024},
    url = {https://openai.com/blog/red-teaming-network},
    urldate = {2025-10-20}
}

@misc{eu2024aiact,
    author = {{European Parliament and Council}},
    title = {Regulation (EU) 2024/1689 laying down harmonised rules on artificial intelligence (Artificial Intelligence Act)},
    year = {2024},
    url = {https://eur-lex.europa.eu/eli/reg/2024/1689/oj},
    urldate = {2025-11-05}
}

@misc{purpur2024building,
    author = {Purpura, Stephen and Li, A. and others},
    title = {Building Safe GenAI Applications: An Overview of Red Teaming for LLMs},
    year = {2024},
    url = {https://arxiv.org/abs/2503.01742},
    urldate = {2025-10-25}
}

@misc{schoepf2025madmax,
    author = {Schoepf, Manuel and others},
    title = {MAD-MAX: Modular Adversarial Red Teaming of LLMs},
    year = {2025},
    url = {https://arxiv.org/abs/2503.06253},
    urldate = {2025-11-01}
}

@misc{belaire2024automatic,
    author = {Belaire, Nathan and others},
    title = {Automatic LLM Red Teaming},
    year = {2024},
    url = {https://arxiv.org/abs/2508.04451},
    urldate = {2025-10-30}
}